{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=16GYHdSWS3iMYwMPv5FpeDZN2rH7PR0F2\n",
      "From (redirected): https://drive.google.com/uc?id=16GYHdSWS3iMYwMPv5FpeDZN2rH7PR0F2&confirm=t&uuid=a0999c68-1627-4209-9515-507d86288072\n",
      "To: /Users/rudyorre/ViT/data.tar.gz\n",
      " 22%|████████▋                               | 100M/460M [00:12<00:48, 7.46MB/s]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rudyorre/ViT/venv/bin/gdown\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/rudyorre/ViT/venv/lib/python3.10/site-packages/gdown/cli.py\", line 156, in main\n",
      "    filename = download(\n",
      "  File \"/Users/rudyorre/ViT/venv/lib/python3.10/site-packages/gdown/download.py\", line 334, in download\n",
      "    for chunk in res.iter_content(chunk_size=CHUNK_SIZE):\n",
      "  File \"/Users/rudyorre/ViT/venv/lib/python3.10/site-packages/requests/models.py\", line 816, in generate\n",
      "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
      "  File \"/Users/rudyorre/ViT/venv/lib/python3.10/site-packages/urllib3/response.py\", line 628, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/Users/rudyorre/ViT/venv/lib/python3.10/site-packages/urllib3/response.py\", line 567, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/Users/rudyorre/ViT/venv/lib/python3.10/site-packages/urllib3/response.py\", line 533, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py\", line 1130, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n",
      " 22%|████████▊                               | 101M/460M [00:13<00:46, 7.75MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "!gdown 16GYHdSWS3iMYwMPv5FpeDZN2rH7PR0F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "\n",
    "def setup(file_link_dict={}, folder_name='Assignment3'):\n",
    "    # Let's make our assignment directory\n",
    "    CS188_path = './'\n",
    "    os.makedirs(os.path.join(CS188_path, 'Assignment3', 'data'), exist_ok=True)\n",
    "    # Now, let's specify the assignment path we will be working with as the root.\n",
    "    root_dir = os.path.join(CS188_path, 'Assignment3')\n",
    "    # Open the tar.gz file\n",
    "    tar = tarfile.open(\"data.tar.gz\", \"r:gz\")\n",
    "    # Extract the file \"./Assignment2/data\" folder\n",
    "    total_size = sum(f.size for f in tar.getmembers())\n",
    "    with tqdm(total=total_size, unit=\"B\", unit_scale=True, desc=\"Extracting tar.gz file\") as pbar:\n",
    "        for member in tar.getmembers():\n",
    "            tar.extract(member, os.path.join(root_dir, 'data'))\n",
    "            pbar.update(member.size)\n",
    "    # Close the tar.gz file\n",
    "    tar.close()\n",
    "    # Next, we download the train/val/test txt files:\n",
    "    for file_name, file_link in file_link_dict.items():\n",
    "        print(f'Downloding {file_name}.txt from {file_link}')\n",
    "        urllib.request.urlretrieve(file_link, f'{root_dir}/data/{file_name}.txt')\n",
    "    return root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting tar.gz file: 100%|████████████████████| 566M/566M [00:18<00:00, 31.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloding train.txt from https://raw.githubusercontent.com/CSAILVision/miniplaces/master/data/train.txt\n",
      "Downloding val.txt from https://raw.githubusercontent.com/CSAILVision/miniplaces/master/data/val.txt\n"
     ]
    }
   ],
   "source": [
    "val_url = 'https://raw.githubusercontent.com/CSAILVision/miniplaces/master/data/val.txt'\n",
    "train_url = 'https://raw.githubusercontent.com/CSAILVision/miniplaces/master/data/train.txt'\n",
    "root_dir = setup(\n",
    "    file_link_dict={'train':train_url, 'val':val_url},\n",
    "    folder_name='Assignment3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define data transformation\n",
    "# You can copy your data transform from Assignment2. \n",
    "# Notice we are resize images to 128x128 instead of 64x64.\n",
    "data_transform = transforms.Compose([\n",
    "    ################# Your Implementations #####################################\n",
    "    # TODO: Resize image to 128x128\n",
    "    transforms.Resize((128, 128)),\n",
    "    ################# End of your Implementations ##############################\n",
    "    transforms.ToTensor(),\n",
    "    ################# Your Implementations #####################################\n",
    "    # TODO: Normalize image using ImageNet statistics\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ################# End of your Implementations ##############################\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can copy your dataset from Assignment2. \n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class MiniPlaces(Dataset):\n",
    "    def __init__(self, root_dir, split, transform=None, label_dict=None):\n",
    "        \"\"\"\n",
    "        Initialize the MiniPlaces dataset with the root directory for the images, \n",
    "        the split (train/val/test), an optional data transformation, \n",
    "        and an optional label dictionary.\n",
    "        \n",
    "        Args:\n",
    "            root_dir (str): Root directory for the MiniPlaces images.\n",
    "            split (str): Split to use ('train', 'val', or 'test').\n",
    "            transform (callable, optional): Optional data transformation to apply to the images.\n",
    "            label_dict (dict, optional): Optional dictionary mapping integer labels to class names.\n",
    "        \"\"\"\n",
    "        assert split in ['train', 'val', 'test']\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.filenames = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Take a second to think why we need this line.\n",
    "        # Hints: training set / validation set / test set.\n",
    "        self.label_dict = label_dict if label_dict is not None else {}\n",
    "\n",
    "        # You should\n",
    "        #   1. Load the train/val text file based on the `split` argument and\n",
    "        #     store the image filenames and labels.\n",
    "        #   2. Extract the class names from the image filenames and store them in \n",
    "        #     self.label_dict.\n",
    "        #   3. Construct a label dict that maps integer labels to class names, if \n",
    "        #     the current split is \"train\" \n",
    "        ################# Your Implementations #####################################\n",
    "         # Test set\n",
    "        if split == 'test':\n",
    "            for file in os.listdir(os.path.join(root_dir, 'images', split)):\n",
    "              self.filenames.append(file[:-4])\n",
    "            self.filenames.sort()\n",
    "            return\n",
    "\n",
    "        # Train/Val sets\n",
    "        with open(os.path.join(root_dir, split + '.txt')) as open_file:\n",
    "            for line in open_file:\n",
    "                filename, label = line.strip().split()\n",
    "                self.filenames.append(filename)\n",
    "                self.labels.append(int(label))\n",
    "                if split == 'train':\n",
    "                    self.label_dict[int(label)] = filename.split('/')[2]\n",
    "        ################# End of your Implementations ##############################\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of images in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            int: Number of images in the dataset.\n",
    "        \"\"\"\n",
    "        ################# Your Implementations #####################################\n",
    "        # Return the number of images in the dataset\n",
    "        return len(self.filenames)\n",
    "        ################# End of your Implementations ##############################\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return a single image and its corresponding label when given an index.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Index of the image to retrieve.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Tuple containing the image and its label.\n",
    "        \"\"\"\n",
    "        image = None\n",
    "        label = None\n",
    "        ################# Your Implementations #####################################\n",
    "        # Load and preprocess image using self.root_dir, \n",
    "        # self.filenames[idx], and self.transform (if specified)\n",
    "        filename = self.filenames[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.split == 'test':\n",
    "            img_path = os.path.join(self.root_dir, 'images', 'test', filename + '.jpg')\n",
    "            return self.transform(Image.open(img_path)), filename\n",
    "        \n",
    "        img_path = os.path.join(self.root_dir, 'images', filename)\n",
    "        image = Image.open(img_path)\n",
    "        image = self.transform(image)\n",
    "        ################# End of your Implementations ##############################\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs):\n",
    "    \"\"\"\n",
    "    Train the MLP classifier on the training set and evaluate it on the validation set every epoch.\n",
    "    \n",
    "    Args:\n",
    "        model (MLP): MLP classifier to train.\n",
    "        train_loader (torch.utils.data.DataLoader): Data loader for the training set.\n",
    "        val_loader (torch.utils.data.DataLoader): Data loader for the validation set.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer to use for training.\n",
    "        criterion (callable): Loss function to use for training.\n",
    "        device (torch.device): Device to use for training.\n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "    \"\"\"\n",
    "    # Place model on device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        # Use tqdm to display a progress bar during training\n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}') as pbar:\n",
    "            for inputs, labels in train_loader:\n",
    "                # Move inputs and labels to device\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero out gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Compute the logits and loss\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                # Backpropagate the loss\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update the weights\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update the progress bar\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # Evaluate the model on the validation set\n",
    "        avg_loss, accuracy = evaluate(model, val_loader, criterion, device)\n",
    "        print(f'Validation set: Average loss = {avg_loss:.4f}, Accuracy = {accuracy:.4f}')\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluate the MLP classifier on the test set.\n",
    "    \n",
    "    Args:\n",
    "        model (MLP): MLP classifier to evaluate.\n",
    "        test_loader (torch.utils.data.DataLoader): Data loader for the test set.\n",
    "        criterion (callable): Loss function to use for evaluation.\n",
    "        device (torch.device): Device to use for evaluation.\n",
    "        \n",
    "    Returns:\n",
    "        float: Average loss on the test set.\n",
    "        float: Accuracy on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        for inputs, labels in test_loader:\n",
    "            # Move inputs and labels to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Compute the logits and loss\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "            num_samples += len(inputs)\n",
    "            \n",
    "    # Compute the average loss and accuracy\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = num_correct / num_samples\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please set GPU via Edit -> Notebook Settings.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device == torch.device('cuda'):\n",
    "    print(f'Using device: {device}. Good to go!')\n",
    "else:\n",
    "    print('Please set GPU via Edit -> Notebook Settings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit import ViT\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#Define the model, optimizer, and criterion (loss_fn)\n",
    "model = ViT(\n",
    "    image_size=128,\n",
    "    patch_size=16,\n",
    "    num_classes=100,\n",
    "    dim=192,\n",
    "    depth=8,\n",
    "    heads=4,\n",
    "    dim_head=48,\n",
    "    mlp_dim=768,\n",
    "    dropout=0.1,\n",
    "    emb_dropout=0.1\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3,)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the dataset and data transform with flatten functions appended\n",
    "data_root = os.path.join(root_dir, 'data')\n",
    "train_dataset = MiniPlaces(\n",
    "    root_dir=data_root,\n",
    "    split='train', \n",
    "    transform=data_transform\n",
    ")\n",
    "\n",
    "val_dataset = MiniPlaces(\n",
    "    root_dir=data_root,\n",
    "    split='val', \n",
    "    transform=data_transform,\n",
    "    label_dict=train_dataset.label_dict\n",
    ")\n",
    "\n",
    "# Define the batch size and number of workers\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "# Define the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "# Train the model\n",
    "if __name__ == __main__:\n",
    "#    train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "be4b5604848afc59d91aec7647343447964cd3ca51d4b95ec174244522810134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
